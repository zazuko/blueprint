# Docker stack

You can start the stack with a full demo dataset:

```sh
docker compose \
  --profile full-demo-dataset \
  up -d --build
```

You can also add a basic Kubernetes + OCI demo dataset (see in a next section how to build them), by running the following command:

```sh
docker compose \
  --profile basic-metadata \
  --profile k8s-demo-data \
  up -d --build
```

Here is where each component is exposed:

- Blueprint: http://127.0.0.1:8081/
- Fuseki (the triple store): http://127.0.0.1:3030/ (credentials: `admin` / `admin`)
- Trifid: http://127.0.0.1:8080/

## Generate triples

Here is how some of the triples were generated, in case you want to generate your own, based on your own data.

### Kubernetes triples

#### Without a Kubernetes cluster

Once you have started the Docker Compose stack, you can run the following command (this is the one that was used in the ):

```sh
docker compose --profile k8s-demo-data up -d --build
```

This will run a job that will import the triples that are in the `demo-data/k8s.ttl` file.

Those triples were generated by starting a Kubernetes cluster using Docker Desktop.

This will help you populate the store with some useful data without the need of running a Kubernetes cluster, so that you can start playing with them.

To learn more about how those triples were generated, read the next section.

#### Using an existing Kubernetes cluster

This requires you to have access to a Kubernetes cluster.

If you want to quickly get a cluster locally, just:

- [enable Kubernetes from Docker Desktop](https://docs.docker.com/desktop/kubernetes/) if you are using MacOS or Windows,
- [install microk8s](https://microk8s.io/#install-microk8s) + run the following command: `microk8s config > ~/.kube/config`, if you are using Linux.

By default it will use the selected `context` (you get it by running: `config current-context`) that you have when running [`kubectl`](https://kubernetes.io/docs/tasks/tools/#kubectl).
For more information, you can read the README of the project here: https://github.com/zazuko/k8s-rdf-exporter.

To generate triples, you can run the following command within this directory:

```sh
mkdir -p ./volumes/k8s-data/

npx @zazuko/k8s-rdf-exporter@latest \
  --base-iri=http://127.0.0.1:8080/k8s/ \
  --base-iri-oci=http://127.0.0.1:8080/oci/ > ./volumes/k8s-data/data.ttl
```

The `demo-data/k8s.ttl` was generated that way, using a Kubernetes cluster created using Docker Desktop.

Importing generated triples to the Fuseki triplestore (run one of both):

- for the custom file with your cluster (`volumes/k8s-data/data.ttl`): `docker compose --profile k8s-custom-data up -d --build`
- for the demo file (`demo-data/k8s.ttl`): `docker compose --profile k8s-demo-data up -d --build`

## Reset everything

To reset everything (it will also remove your custom k8s data if any), you can run the following command:

```sh
docker compose --profile='*' down
rm -rf ./volumes/
```

This can be useful if you want to start from scratch and try other kinds of data.
