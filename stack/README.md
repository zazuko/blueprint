# Docker stack

## Table of Contents

- [Docker stack](#docker-stack)
- [Generate triples](#generate-triples)
    - [Kubernetes triples](#kubernetes-triples)
        - [Without a Kubernetes cluster](#without-a-kubernetes-cluster)
        - [Using an existing Kubernetes cluster](#using-an-existing-kubernetes-cluster)
- [Reset everything](#reset-everything)

## Run the stack


###Â Full demo dataset
You can start the stack with a [full demo dataset](https://download.zazukoians.org/blueprint/demo-data.nt):

```sh
docker compose --profile full-demo-dataset up -d --build
```

## Basic Kubernetes + OCI dataset
You can also add a basic Kubernetes + OCI demo dataset, by running the following command:

```sh
docker compose --profile basic-metadata --profile k8s-demo-data up -d --build
```

You will see in a next section how to build this dataset by yourself, in case you want to try with your own Kubernetes cluster.

Here is where each component is exposed:

- Blueprint: http://127.0.0.1:8081/
- Fuseki (the triple store): http://127.0.0.1:3030/ (credentials: `admin` / `admin`)
- Trifid: http://127.0.0.1:8080/

## Generate triples

Here is how some of the triples were generated, in case you want to generate your own, based on your own data.

### Kubernetes triples

#### Without a Kubernetes cluster

Once you have started the Docker Compose stack, you can run the following command (this is the one that was used in the first part already):

```sh
docker compose --profile k8s-demo-data up -d --build
```

This will run a job that will import the triples that are in the `demo-data/k8s.ttl` file.

Those triples were generated by starting a Kubernetes cluster using Docker Desktop.

This will help you populate the store with some useful data without the need of running a Kubernetes cluster, so that you can start playing with them.

To learn more about how those triples were generated, read the next section.

#### Using an existing Kubernetes cluster

This requires you to have access to a Kubernetes cluster.

If you want to quickly get a cluster locally, just:

- [enable Kubernetes from Docker Desktop](https://docs.docker.com/desktop/kubernetes/) if you are using MacOS or Windows,
- [install microk8s](https://microk8s.io/#install-microk8s) + run the following command: `microk8s config > ~/.kube/config`, if you are using Linux.

By default it will use the selected `context` (you get it by running: `config current-context`) that you have when running [`kubectl`](https://kubernetes.io/docs/tasks/tools/#kubectl).
For more information, you can read the README of the project here: https://github.com/zazuko/k8s-rdf-exporter.

To generate triples, you can run the following command within this directory:

```sh
mkdir -p ./volumes/k8s-data/

npx @zazuko/k8s-rdf-exporter@latest --base-iri=http://127.0.0.1:8080/k8s/ --base-iri-oci=http://127.0.0.1:8080/oci/ > ./volumes/k8s-data/data.ttl
```

The `demo-data/k8s.ttl` was generated that way, using a Kubernetes cluster created using Docker Desktop.

Importing generated triples to the Fuseki triplestore (run one of both):

- for the custom file with your cluster (`volumes/k8s-data/data.ttl`): `docker compose --profile k8s-custom-data up -d --build`
- for the demo file (`demo-data/k8s.ttl`): `docker compose --profile k8s-demo-data up -d --build`

Running one of the above commands will import the triples into the Fuseki triplestore and removes the previous k8s data, not the other data or any metadata.

## Reset everything

To reset everything (it will also remove your custom k8s data if any), you can run the following command:

```sh
docker compose --profile='*' down
rm -rf ./volumes/
```

This can be useful if you want to start from scratch and try other kinds of data.
